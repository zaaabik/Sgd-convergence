{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import create_input, create_labels, init_weights\n",
    "from Net import Net, ResnetNet\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10_000\n",
    "experiments = 1\n",
    "lr = 1e-4\n",
    "batch_size = 200\n",
    "epochs = 50\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "net_star = Net()\n",
    "net_star = init_weights(net_star)\n",
    "X = create_input(n)\n",
    "y = net_star(X).detach()\n",
    "\n",
    "dataset = data.TensorDataset(X, y)\n",
    "dataloader = data.DataLoader(dataset, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss 0.0\n"
     ]
    }
   ],
   "source": [
    "epoch_losses = []\n",
    "for x,y in dataloader:\n",
    "    output = net_star(x)\n",
    "    loss = criterion(output, y)\n",
    "    \n",
    "    epoch_losses.append(loss.item())\n",
    "        \n",
    "print(f'Epoch {0} loss {np.mean(epoch_losses)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a0d1ac881fd40dc80bf9af33d76b5f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss 12.842120008468628 norm 7.027131080627441\n",
      "Epoch 1 loss 6.305380125045776 norm 7.028593063354492\n",
      "Epoch 2 loss 6.86137357711792 norm 7.055171489715576\n",
      "Epoch 3 loss 8.642828149795532 norm 7.077916622161865\n",
      "Epoch 4 loss 8.428256673812866 norm 7.10316801071167\n",
      "Epoch 5 loss 7.624585418701172 norm 7.16804838180542\n",
      "Epoch 6 loss 7.823367547988892 norm 7.265873908996582\n",
      "Epoch 7 loss 7.659933414459228 norm 7.353884220123291\n",
      "Epoch 8 loss 7.127183628082276 norm 7.4201788902282715\n",
      "Epoch 9 loss 7.824785194396973 norm 7.474297523498535\n",
      "Epoch 10 loss 8.95873191833496 norm 7.5291748046875\n",
      "Epoch 11 loss 9.708812713623047 norm 7.5926008224487305\n",
      "Epoch 12 loss 9.272164707183839 norm 7.666447162628174\n",
      "Epoch 13 loss 8.723744697570801 norm 7.755759239196777\n",
      "Epoch 14 loss 10.072256488800049 norm 7.845449447631836\n",
      "Epoch 15 loss 10.759170875549316 norm 7.911159992218018\n",
      "Epoch 16 loss 9.870124616622924 norm 7.957721710205078\n",
      "Epoch 17 loss 10.160139837265014 norm 8.00733470916748\n",
      "Epoch 18 loss 12.115749168395997 norm 8.06734848022461\n",
      "Epoch 19 loss 13.282188148498536 norm 8.131392478942871\n",
      "Epoch 20 loss 12.175957050323486 norm 8.204306602478027\n",
      "Epoch 21 loss 11.25525297164917 norm 8.296056747436523\n",
      "Epoch 22 loss 12.178927898406982 norm 8.396074295043945\n",
      "Epoch 23 loss 13.098505535125732 norm 8.482189178466797\n",
      "Epoch 24 loss 13.14117197036743 norm 8.545883178710938\n",
      "Epoch 25 loss 13.404520835876465 norm 8.592057228088379\n",
      "Epoch 26 loss 14.33417818069458 norm 8.627655982971191\n",
      "Epoch 27 loss 15.26886058807373 norm 8.661463737487793\n",
      "Epoch 28 loss 15.320310745239258 norm 8.701695442199707\n",
      "Epoch 29 loss 14.05416790008545 norm 8.760274887084961\n",
      "Epoch 30 loss 12.66065486907959 norm 8.851405143737793\n",
      "Epoch 31 loss 13.128952465057374 norm 8.971906661987305\n",
      "Epoch 32 loss 15.233478374481201 norm 9.096624374389648\n",
      "Epoch 33 loss 16.862955150604247 norm 9.198833465576172\n",
      "Epoch 34 loss 16.79172777175903 norm 9.267317771911621\n",
      "Epoch 35 loss 15.707759532928467 norm 9.30595588684082\n",
      "Epoch 36 loss 14.75197250366211 norm 9.326763153076172\n",
      "Epoch 37 loss 14.158849296569825 norm 9.346078872680664\n",
      "Epoch 38 loss 14.011165084838867 norm 9.381465911865234\n",
      "Epoch 39 loss 14.838646621704102 norm 9.442599296569824\n",
      "Epoch 40 loss 16.47691625595093 norm 9.525738716125488\n",
      "Epoch 41 loss 17.569947528839112 norm 9.619122505187988\n",
      "Epoch 42 loss 17.059394245147704 norm 9.714999198913574\n",
      "Epoch 43 loss 15.50008041381836 norm 9.812743186950684\n",
      "Epoch 44 loss 14.317522659301758 norm 9.912303924560547\n",
      "Epoch 45 loss 14.356559219360351 norm 10.008990287780762\n",
      "Epoch 46 loss 15.229416007995605 norm 10.093925476074219\n",
      "Epoch 47 loss 15.914098587036133 norm 10.159294128417969\n",
      "Epoch 48 loss 15.785977439880371 norm 10.204565048217773\n",
      "Epoch 49 loss 15.190314083099365 norm 10.23756217956543\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_iteration_losses = []\n",
    "test_iteration_acc = []\n",
    "\n",
    "for experiment in range(experiments):\n",
    "    net = Net()\n",
    "    net = init_weights(net)\n",
    "    optimizer = optim.Adam(net.parameters(), lr)\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        epoch_losses = []\n",
    "        for x, y in dataloader:\n",
    "            output = net(x)\n",
    "            loss = criterion(output, y)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_losses.append(loss.item())\n",
    "        \n",
    "        norm = torch.norm(top_weights - net.state_dict()['linear.weight'])\n",
    "        print(f'Epoch {epoch} loss {np.mean(epoch_losses)} norm {norm}' )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10_000\n",
    "experiments = 1\n",
    "lr = 1e-3\n",
    "batch_size = 200\n",
    "epochs = 50\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "net_star = ResnetNet()\n",
    "net_star = init_weights(net_star)\n",
    "X = create_input(n)\n",
    "y = net_star(X).detach()\n",
    "\n",
    "dataset = data.TensorDataset(X, y)\n",
    "dataloader = data.DataLoader(dataset, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b464a096888f426ea44bcbda03eaca5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss 15.18572491645813 norm 8.731208801269531\n",
      "Epoch 1 loss 30.585151290893556 norm 15.480223655700684\n",
      "Epoch 2 loss 33.781835289001464 norm 23.864398956298828\n",
      "Epoch 3 loss 54.68367988586426 norm 33.15032196044922\n",
      "Epoch 4 loss 53.205555572509766 norm 43.866676330566406\n",
      "Epoch 5 loss 48.237593231201174 norm 54.421730041503906\n",
      "Epoch 6 loss 46.6680029296875 norm 65.4554443359375\n",
      "Epoch 7 loss 44.90243804931641 norm 76.20547485351562\n",
      "Epoch 8 loss 43.28778121948242 norm 87.4575424194336\n",
      "Epoch 9 loss 42.400784759521486 norm 97.93953704833984\n",
      "Epoch 10 loss 40.048274536132816 norm 109.13246154785156\n",
      "Epoch 11 loss 39.94418029785156 norm 119.76437377929688\n",
      "Epoch 12 loss 38.89743812561035 norm 130.28604125976562\n",
      "Epoch 13 loss 38.687261962890624 norm 141.58578491210938\n",
      "Epoch 14 loss 38.57093830108643 norm 151.97598266601562\n",
      "Epoch 15 loss 38.121747169494625 norm 162.46632385253906\n",
      "Epoch 16 loss 37.45334403991699 norm 173.55322265625\n",
      "Epoch 17 loss 37.422615966796876 norm 183.9346923828125\n",
      "Epoch 18 loss 37.63981601715088 norm 194.1402587890625\n",
      "Epoch 19 loss 37.15851192474365 norm 205.07325744628906\n",
      "Epoch 20 loss 37.05085826873779 norm 215.8505859375\n",
      "Epoch 21 loss 37.12671245574951 norm 225.7913360595703\n",
      "Epoch 22 loss 36.952585983276364 norm 235.9165496826172\n",
      "Epoch 23 loss 36.7460322189331 norm 246.72634887695312\n",
      "Epoch 24 loss 36.71049690246582 norm 257.32501220703125\n",
      "Epoch 25 loss 36.731210975646974 norm 267.3392333984375\n",
      "Epoch 26 loss 36.80082939147949 norm 277.4931945800781\n",
      "Epoch 27 loss 37.12950740814209 norm 288.08831787109375\n",
      "Epoch 28 loss 37.31865589141846 norm 298.5115966796875\n",
      "Epoch 29 loss 36.662711753845215 norm 308.479248046875\n",
      "Epoch 30 loss 35.823774070739745 norm 318.5130920410156\n",
      "Epoch 31 loss 35.77175880432129 norm 328.9825744628906\n",
      "Epoch 32 loss 36.11656436920166 norm 339.49591064453125\n",
      "Epoch 33 loss 36.4492972946167 norm 349.577880859375\n",
      "Epoch 34 loss 36.60304550170898 norm 359.3986511230469\n",
      "Epoch 35 loss 36.7903067779541 norm 369.46258544921875\n",
      "Epoch 36 loss 36.9043798828125 norm 379.8844909667969\n",
      "Epoch 37 loss 36.91608509063721 norm 390.2893981933594\n",
      "Epoch 38 loss 36.888761329650876 norm 400.35113525390625\n",
      "Epoch 39 loss 36.92606945037842 norm 410.2045593261719\n",
      "Epoch 40 loss 36.95361110687256 norm 420.2267761230469\n",
      "Epoch 41 loss 36.83114532470703 norm 430.545654296875\n",
      "Epoch 42 loss 36.748028945922854 norm 440.9007568359375\n",
      "Epoch 43 loss 36.78060054779053 norm 450.9445495605469\n",
      "Epoch 44 loss 36.67212654113769 norm 460.69342041015625\n",
      "Epoch 45 loss 36.56600811004639 norm 470.4744873046875\n",
      "Epoch 46 loss 36.69158130645752 norm 480.5042419433594\n",
      "Epoch 47 loss 36.71317882537842 norm 490.7043151855469\n",
      "Epoch 48 loss 36.624875984191895 norm 500.8259582519531\n",
      "Epoch 49 loss 36.55620761871338 norm 510.72039794921875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_iteration_losses = []\n",
    "test_iteration_acc = []\n",
    "\n",
    "for experiment in range(1):\n",
    "    net = ResnetNet()\n",
    "    net = init_weights(net)\n",
    "    optimizer = optim.SGD(net.parameters(), lr)\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        epoch_losses = []\n",
    "        for x,y in dataloader:\n",
    "            output = net(x)\n",
    "            loss = criterion(output, y)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_losses.append(loss.item())\n",
    "            \n",
    "        norm = torch.norm(top_weights - net.state_dict()['linear.weight'])\n",
    "        print(f'Epoch {epoch} loss {np.mean(epoch_losses)} norm {norm}')\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
